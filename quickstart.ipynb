{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected braintreebank data at: /om2/user/zaho/braintreebank/braintreebank/\n",
      "Sampling rate: 2048 Hz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['ROOT_DIR_BRAINTREEBANK'] = '/om2/user/zaho/braintreebank/braintreebank/' # Feel free to change this to your own path, or define the os variable elsewhere\n",
    "\n",
    "import torch\n",
    "import neuroprobe.config as neuroprobe_config\n",
    "\n",
    "# Make sure the config ROOT_DIR is set correctly\n",
    "print(\"Expected braintreebank data at:\", neuroprobe_config.ROOT_DIR)\n",
    "print(\"Sampling rate:\", neuroprobe_config.SAMPLING_RATE, \"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The BrainTreebankSubject Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electrode labels: ['F3aOFa2', 'F3aOFa3', 'F3aOFa4', 'F3aOFa7', 'F3aOFa8', 'F3aOFa9', 'F3aOFa10', 'F3aOFa11', 'F3aOFa12', 'F3aOFa13', 'F3aOFa14', 'F3aOFa15', 'F3aOFa16', 'F3bIaOFb1', 'F3bIaOFb2', 'F3bIaOFb3', 'F3bIaOFb4', 'F3bIaOFb5', 'F3bIaOFb6', 'F3bIaOFb7', 'F3bIaOFb8', 'F3bIaOFb9', 'F3bIaOFb10', 'F3bIaOFb11', 'F3bIaOFb12', 'F3bIaOFb13', 'F3bIaOFb14', 'F3bIaOFb15', 'F3bIaOFb16', 'F3cId1', 'F3cId2', 'F3cId3', 'F3cId4', 'F3cId5', 'F3cId6', 'F3cId7', 'F3cId8', 'F3cId9', 'T1aIb1', 'T1aIb2', 'T1aIb3', 'T1aIb4', 'T1aIb5', 'T1aIb6', 'T1aIb7', 'T1aIb8', 'T2aA1', 'T2aA2', 'T2aA3', 'T2aA4', 'T2aA5', 'T2aA6', 'T2aA7', 'T2aA8', 'T2aA9', 'T2aA10', 'T2aA11', 'T2aA12', 'T2bHa1', 'T2bHa3', 'T2bHa4', 'T2bHa5', 'T2bHa7', 'T2bHa8', 'T2bHa9', 'T2bHa10', 'T2bHa11', 'T2bHa12', 'T2bHa13', 'T2bHa14', 'T1bIc1', 'T1bIc2', 'T1bIc3', 'T1bIc4', 'T1bIc5', 'T1bIc6', 'T1bIc7', 'T1bIc8', 'F3dIe1', 'F3dIe2', 'F3dIe3', 'F3dIe4', 'F3dIe5', 'F3dIe6', 'F3dIe7', 'F3dIe8', 'F3dIe9', 'F3dIe10', 'F3dIe14', 'T3aHb6', 'T3aHb9', 'T3aHb10', 'T3aHb12', 'T1cIf1', 'T1cIf2', 'T1cIf3', 'T1cIf4', 'T1cIf5', 'T1cIf6', 'T1cIf7', 'T1cIf8', 'T1cIf10', 'T1cIf11', 'T1cIf12', 'T1cIf13', 'T1cIf14', 'T1cIf15', 'T1cIf16', 'T2c4', 'T2c5', 'T2c6', 'T2c7', 'T2c8', 'T3bOT1', 'T3bOT2', 'T3bOT3', 'T3bOT4', 'T3bOT5', 'T3bOT6', 'T3bOT8', 'T3bOT9', 'T3bOT10', 'T3bOT12', 'T2d1', 'T2d2', 'T2d3', 'T2d4', 'T2d5', 'T2d6']\n"
     ]
    }
   ],
   "source": [
    "from neuroprobe.braintreebank_subject import BrainTreebankSubject\n",
    "\n",
    "subject_id = 1\n",
    "\n",
    "# use cache=True to load this trial's neural data into RAM, if you have enough memory!\n",
    "# It will make the loading process faster.\n",
    "subject = BrainTreebankSubject(subject_id, allow_corrupted=False, cache=True, dtype=torch.float32)\n",
    "print(\"Electrode labels:\", subject.electrode_labels) # list of electrode labels\n",
    "\n",
    "# Optionally, subset the electrodes to a specific set of electrodes.\n",
    "# subject.set_electrode_subset(['F3aOFa2', 'F3aOFa3', 'F3aOFa4', 'F3aOFa7']) # if you change this line when using cache=True, you need to clear the cache after: subject.clear_neural_data_cache()\n",
    "# print(\"Electrode labels after subsetting:\", subject.electrode_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the electrode data and electrode coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All neural data shape:\n",
      "torch.Size([129, 21401009])\n",
      "\n",
      "Electrode coordinates (MNI space) of the first 10 electrodes:\n",
      "tensor([[ 76.0103, -49.9502, -25.1740],\n",
      "        [ 75.4765, -50.8993, -22.9590],\n",
      "        [ 81.5899, -49.6018, -13.3198],\n",
      "        [ 81.3702, -47.3542,  -6.0947],\n",
      "        [ 83.1155, -43.3788,   0.5507],\n",
      "        [ 79.8622, -41.9135,   3.7532],\n",
      "        [ 79.1331, -41.2117,   4.8066],\n",
      "        [ 67.2942, -28.6666,  14.7228],\n",
      "        [ 68.9201, -28.2619,  15.2759],\n",
      "        [ 77.7627, -21.2303,  19.6270]])\n"
     ]
    }
   ],
   "source": [
    "trial_id = 1\n",
    "\n",
    "subject.load_neural_data(trial_id)\n",
    "window_from = None\n",
    "window_to = None # if None, the whole trial will be loaded\n",
    "\n",
    "print(\"All neural data shape:\")\n",
    "print(subject.get_all_electrode_data(trial_id, window_from=window_from, window_to=window_to).shape) # (n_electrodes, n_samples). To get the data for a specific electrode, use subject.get_electrode_data(trial_id, electrode_label)\n",
    "\n",
    "print(\"\\nElectrode coordinates (MNI space) of the first 10 electrodes:\")\n",
    "print(subject.get_electrode_coordinates()[:10]) # L, P, I coordinates of the electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The BrainTreebankSubjectTrialBenchmarkDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the dataset: 3500 \n",
      "\n",
      "The first item: (shape = torch.Size([120, 2048]))\n",
      "tensor([[ 32.9645,  27.3818,  20.4699,  ...,   2.1267,  -0.5317,   6.3802],\n",
      "        [ 67.2582,  62.2072,  56.0928,  ...,  44.9274,  42.2690,  49.1809],\n",
      "        [120.9584, 115.3757, 106.6029,  ...,  58.2195,  53.9661,  59.8146],\n",
      "        ...,\n",
      "        [ 15.1530,   7.4436,   3.7218,  ...,  -2.1267,  -5.8485,   2.9243],\n",
      "        [ 26.3184,  19.4065,  14.8872,  ...,  16.4822,  14.3555,  19.9382],\n",
      "        [-13.0263, -17.5456, -23.9258,  ...,   3.4560,   2.6584,  11.1654]])\n",
      "label = 1\n",
      "\n",
      "Electrode labels in the data above in the following order (120 electrodes): ['T1bIc1', 'T1bIc2', 'T1bIc3', 'T1bIc4', 'T1bIc5', 'T1bIc6', 'T1bIc7', 'T1bIc8', 'T1cIf10', 'T1cIf11', 'T1cIf12', 'T1cIf13', 'T1cIf14', 'T1cIf15', 'T1cIf16', 'T1aIb1', 'T1aIb2', 'T1aIb3', 'T1aIb4', 'T1aIb5', 'T1aIb6', 'T1aIb7', 'T1aIb8', 'T3aHb9', 'T3aHb10', 'T1cIf1', 'T1cIf2', 'T1cIf3', 'T1cIf4', 'T1cIf5', 'T1cIf6', 'T1cIf7', 'T1cIf8', 'T2bHa7', 'T2bHa8', 'T2bHa9', 'T2bHa10', 'T2bHa11', 'T2bHa12', 'T2bHa13', 'T2bHa14', 'T3bOT8', 'T3bOT9', 'T3bOT10', 'F3cId1', 'F3cId2', 'F3cId3', 'F3cId4', 'F3cId5', 'F3cId6', 'F3cId7', 'F3cId8', 'F3cId9', 'T2c4', 'T2c5', 'T2c6', 'T2c7', 'T2c8', 'F3bIaOFb1', 'F3bIaOFb2', 'F3bIaOFb3', 'F3bIaOFb4', 'F3bIaOFb5', 'F3bIaOFb6', 'F3bIaOFb7', 'F3bIaOFb8', 'F3bIaOFb9', 'F3bIaOFb10', 'F3bIaOFb11', 'F3bIaOFb12', 'F3bIaOFb13', 'F3bIaOFb14', 'F3bIaOFb15', 'F3bIaOFb16', 'T2d1', 'T2d2', 'T2d3', 'T2d4', 'T2d5', 'T2d6', 'F3aOFa7', 'F3aOFa8', 'F3aOFa9', 'F3aOFa10', 'F3aOFa11', 'F3aOFa12', 'F3aOFa13', 'F3aOFa14', 'F3aOFa15', 'F3aOFa16', 'F3aOFa2', 'F3aOFa3', 'F3aOFa4', 'T3bOT1', 'T3bOT2', 'T3bOT3', 'T3bOT4', 'T3bOT5', 'T3bOT6', 'T2bHa3', 'T2bHa4', 'T2bHa5', 'F3dIe1', 'F3dIe2', 'F3dIe3', 'F3dIe4', 'F3dIe5', 'F3dIe6', 'F3dIe7', 'F3dIe8', 'F3dIe9', 'F3dIe10', 'T2aA1', 'T2aA2', 'T2aA3', 'T2aA4', 'T2aA5', 'T2aA6', 'T2aA7', 'T2aA8']\n",
      "\n",
      "NOTE: The electrode labels here are subset to the NEUROPROBE_LITE_ELECTRODES list. Accordingly, there will be fewer electrodes than in the full subject data.\n",
      "This is because the Neuroprobe benchmark only uses a subset of the electrodes for standardized and quick benchmarking. (assuming lite=True which is the default)\n"
     ]
    }
   ],
   "source": [
    "from neuroprobe.datasets import BrainTreebankSubjectTrialBenchmarkDataset\n",
    "\n",
    "# Options for eval_name (from the Neuroprobe paper):\n",
    "#   frame_brightness, global_flow, local_flow, global_flow_angle, local_flow_angle, face_num, volume, pitch, delta_volume, \n",
    "#   delta_pitch, speech, onset, gpt2_surprisal, word_length, word_gap, word_index, word_head_pos, word_part_speech, speaker\n",
    "eval_name = \"volume\"\n",
    "\n",
    "# if True, the dataset will output the indices of the samples in the neural data in a tuple: (index_from, index_to); \n",
    "# if False, the dataset will output the neural data directly\n",
    "output_indices = False\n",
    "\n",
    "start_neural_data_before_word_onset = 0 # the number of samples to start the neural data before each word onset\n",
    "end_neural_data_after_word_onset = neuroprobe_config.SAMPLING_RATE * 1 # the number of samples to end the neural data after each word onset -- here we use 1 second\n",
    "\n",
    "\n",
    "dataset = BrainTreebankSubjectTrialBenchmarkDataset(subject, trial_id, dtype=torch.float32, eval_name=eval_name, output_indices=output_indices, \n",
    "                                                    start_neural_data_before_word_onset=start_neural_data_before_word_onset, end_neural_data_after_word_onset=end_neural_data_after_word_onset,\n",
    "                                                    lite=True) # the default is Neuroprobe Lite for standardized and quick benchmarking. Feel free to set lite=false if trying to access the Full dataset.\n",
    "# P.S. Allow partial cache -- whether to allow partial caching of the neural data, if only part of it is needed for this particular dataset. Better set to False when doing multiple evals back to back, but better set to True when doing a single eval.\n",
    "\n",
    "print(\"Items in the dataset:\", len(dataset), \"\\n\")\n",
    "print(f\"The first item: (shape = {dataset[0][0].shape})\", dataset[0][0], f\"label = {dataset[0][1]}\", sep=\"\\n\")\n",
    "print(\"\")\n",
    "print(f\"Electrode labels in the data above in the following order ({len(dataset.electrode_labels)} electrodes):\", dataset.electrode_labels)\n",
    "\n",
    "print(\"\\nNOTE: The electrode labels here are subset to the NEUROPROBE_LITE_ELECTRODES list. Accordingly, there will be fewer electrodes than in the full subject data.\")\n",
    "print(\"This is because the Neuroprobe benchmark only uses a subset of the electrodes for standardized and quick benchmarking. (assuming lite=True which is the default)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[ 32.9645,  27.3818,  20.4699,  ...,   2.1267,  -0.5317,   6.3802],\n",
       "         [ 67.2582,  62.2072,  56.0928,  ...,  44.9274,  42.2690,  49.1809],\n",
       "         [120.9584, 115.3757, 106.6029,  ...,  58.2195,  53.9661,  59.8146],\n",
       "         ...,\n",
       "         [ 15.1530,   7.4436,   3.7218,  ...,  -2.1267,  -5.8485,   2.9243],\n",
       "         [ 26.3184,  19.4065,  14.8872,  ...,  16.4822,  14.3555,  19.9382],\n",
       "         [-13.0263, -17.5456, -23.9258,  ...,   3.4560,   2.6584,  11.1654]]),\n",
       " 'label': 1,\n",
       " 'electrode_labels': ['T1bIc1',\n",
       "  'T1bIc2',\n",
       "  'T1bIc3',\n",
       "  'T1bIc4',\n",
       "  'T1bIc5',\n",
       "  'T1bIc6',\n",
       "  'T1bIc7',\n",
       "  'T1bIc8',\n",
       "  'T1cIf10',\n",
       "  'T1cIf11',\n",
       "  'T1cIf12',\n",
       "  'T1cIf13',\n",
       "  'T1cIf14',\n",
       "  'T1cIf15',\n",
       "  'T1cIf16',\n",
       "  'T1aIb1',\n",
       "  'T1aIb2',\n",
       "  'T1aIb3',\n",
       "  'T1aIb4',\n",
       "  'T1aIb5',\n",
       "  'T1aIb6',\n",
       "  'T1aIb7',\n",
       "  'T1aIb8',\n",
       "  'T3aHb9',\n",
       "  'T3aHb10',\n",
       "  'T1cIf1',\n",
       "  'T1cIf2',\n",
       "  'T1cIf3',\n",
       "  'T1cIf4',\n",
       "  'T1cIf5',\n",
       "  'T1cIf6',\n",
       "  'T1cIf7',\n",
       "  'T1cIf8',\n",
       "  'T2bHa7',\n",
       "  'T2bHa8',\n",
       "  'T2bHa9',\n",
       "  'T2bHa10',\n",
       "  'T2bHa11',\n",
       "  'T2bHa12',\n",
       "  'T2bHa13',\n",
       "  'T2bHa14',\n",
       "  'T3bOT8',\n",
       "  'T3bOT9',\n",
       "  'T3bOT10',\n",
       "  'F3cId1',\n",
       "  'F3cId2',\n",
       "  'F3cId3',\n",
       "  'F3cId4',\n",
       "  'F3cId5',\n",
       "  'F3cId6',\n",
       "  'F3cId7',\n",
       "  'F3cId8',\n",
       "  'F3cId9',\n",
       "  'T2c4',\n",
       "  'T2c5',\n",
       "  'T2c6',\n",
       "  'T2c7',\n",
       "  'T2c8',\n",
       "  'F3bIaOFb1',\n",
       "  'F3bIaOFb2',\n",
       "  'F3bIaOFb3',\n",
       "  'F3bIaOFb4',\n",
       "  'F3bIaOFb5',\n",
       "  'F3bIaOFb6',\n",
       "  'F3bIaOFb7',\n",
       "  'F3bIaOFb8',\n",
       "  'F3bIaOFb9',\n",
       "  'F3bIaOFb10',\n",
       "  'F3bIaOFb11',\n",
       "  'F3bIaOFb12',\n",
       "  'F3bIaOFb13',\n",
       "  'F3bIaOFb14',\n",
       "  'F3bIaOFb15',\n",
       "  'F3bIaOFb16',\n",
       "  'T2d1',\n",
       "  'T2d2',\n",
       "  'T2d3',\n",
       "  'T2d4',\n",
       "  'T2d5',\n",
       "  'T2d6',\n",
       "  'F3aOFa7',\n",
       "  'F3aOFa8',\n",
       "  'F3aOFa9',\n",
       "  'F3aOFa10',\n",
       "  'F3aOFa11',\n",
       "  'F3aOFa12',\n",
       "  'F3aOFa13',\n",
       "  'F3aOFa14',\n",
       "  'F3aOFa15',\n",
       "  'F3aOFa16',\n",
       "  'F3aOFa2',\n",
       "  'F3aOFa3',\n",
       "  'F3aOFa4',\n",
       "  'T3bOT1',\n",
       "  'T3bOT2',\n",
       "  'T3bOT3',\n",
       "  'T3bOT4',\n",
       "  'T3bOT5',\n",
       "  'T3bOT6',\n",
       "  'T2bHa3',\n",
       "  'T2bHa4',\n",
       "  'T2bHa5',\n",
       "  'F3dIe1',\n",
       "  'F3dIe2',\n",
       "  'F3dIe3',\n",
       "  'F3dIe4',\n",
       "  'F3dIe5',\n",
       "  'F3dIe6',\n",
       "  'F3dIe7',\n",
       "  'F3dIe8',\n",
       "  'F3dIe9',\n",
       "  'F3dIe10',\n",
       "  'T2aA1',\n",
       "  'T2aA2',\n",
       "  'T2aA3',\n",
       "  'T2aA4',\n",
       "  'T2aA5',\n",
       "  'T2aA6',\n",
       "  'T2aA7',\n",
       "  'T2aA8'],\n",
       " 'metadata': {'subject_identifier': 'btbank1',\n",
       "  'trial_id': 1,\n",
       "  'sampling_rate': 2048}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optionally, you can request the output_dict=True to get the data as a dictionary with a bunch of metadata.\n",
    "dataset.output_dict = True\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits\n",
    "\n",
    "In this example, we generate train/test splits for the Single Subject Single Movie (SS-SM) evaluation.\n",
    "\n",
    "All options: generate_splits_SS_SM, generate_splits_SS_DM, generate_splits_DS_DM, generate_splits_DS_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_datasets) = len(test_datasets) = k_folds = 2\n"
     ]
    }
   ],
   "source": [
    "import neuroprobe.train_test_splits as neuroprobe_train_test_splits\n",
    "\n",
    "# train_datasets and test_datasets are arrays of length k_folds, each element is a BrainTreebankSubjectTrialBenchmarkDataset for the train/test split\n",
    "train_datasets, test_datasets = neuroprobe_train_test_splits.generate_splits_SS_SM(subject, trial_id, eval_name, dtype=torch.float32, \n",
    "                                                                                # Put the dataset parameters here\n",
    "                                                                                output_indices=output_indices, start_neural_data_before_word_onset=start_neural_data_before_word_onset, end_neural_data_after_word_onset=end_neural_data_after_word_onset,\n",
    "                                                                                lite=True)\n",
    "print(\"len(train_datasets) = len(test_datasets) = k_folds =\", len(train_datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Linear Regression on SS_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 2\n",
      "\t Train accuracy: 1.000 | Test accuracy: 0.598\n",
      "Fold 2 of 2\n",
      "\t Train accuracy: 1.000 | Test accuracy: 0.570\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "for fold_idx in range(len(train_datasets)):\n",
    "    print(f\"Fold {fold_idx+1} of {len(train_datasets)}\")\n",
    "    train_dataset = train_datasets[fold_idx]\n",
    "    test_dataset = test_datasets[fold_idx]\n",
    "\n",
    "    # Convert PyTorch dataset to numpy arrays for scikit-learn\n",
    "    X_train = np.array([item[0].flatten() for item in train_dataset])\n",
    "    y_train = np.array([item[1] for item in train_dataset])\n",
    "    X_test = np.array([item[0].flatten() for item in test_dataset])\n",
    "    y_test = np.array([item[1] for item in test_dataset])\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train logistic regression\n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000, tol=1e-3)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(f\"\\t Train accuracy: {train_score:.3f} | Test accuracy: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BFM Local (.venv)",
   "language": "python",
   "name": "bfm_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
